{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c76589",
   "metadata": {},
   "source": [
    "Phase 1 Summary:\n",
    "\n",
    "In phase 1 we introduced our dataset 'Diamonds' and our intention for using this dataset to predict the price of diamonds based on their physical attributes. \n",
    "\n",
    "To achieve an accurate model for predicting a diamond's price, our initial task included cleaning & preprocessing the data. This involved checking for incorrect & missing values, looking at the amount of unique values, and checking the datatypes of each variable. We found records which included extreme values for the variables y and z, as well as records which included a measure of 0 for x, y and z. We removed these values as the likelihood they were meaniningful values was very low. \n",
    "\n",
    "We then began investigating the distribution of certain variables, plotting their value distribution, and their values against price.\n",
    "\n",
    "We observed that the carat variable was multimodal, with large groupings around multiples of 1 and then observable peaks again at multiples of .1. In our literature review we explored an idea of 'magic numbers' which might explain this, the theory is that jewellers would be aiming for round numbers when working with diamonds.\n",
    "\n",
    "We discovered in exploring the variable table, that it seemingly had little to no influence on price, as for almost any record of table, you could find many records outside of the upper and lower quartiles. When investigating depth we found a similar graph when plotted against price.\n",
    "\n",
    "One of the most helpful graphs for us was a scatterplot of carat against price, where each record is colored by clarity. This helped to indicate that carat had a much larger effect on price than clarity. \n",
    "\n",
    "In our literature review, we discussed the conditions of the market that influence the price of the diamonds. In particular we discussed the way in which e-commerce has the effect of changing the demand of diamonds into that of a commodity, rather than their current luxury item status. Another discussion involved the 'magic numbers' discussed earlier.\n",
    "\n",
    "The conclusion of our phase 1 report included reasonings that drive our interest in predicting diamond prices, a summary of our data processing & cleaning, as well as our findings from variable exploration.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29144be8",
   "metadata": {},
   "source": [
    "Critique and limitations:\n",
    "\n",
    "In our full model the condition number given to us by the statsmodels Ordinary Least Squares fit summary is large, at 11,700. This could be as all our data are to the right of price = 0, causing a high sensitivity around the y intercept. We can observe strange modelling in this area where the model suggests negative prices for diamonds with certain physical attributes, however a negative price is not possible for this object. Seeing as we are not interested in our model giving an accurate y intercept, as a price of zero is not possible, this is not of great concern.\n",
    "\n",
    "When plotting actual price against predicted price with the full model and full dataset we see a slight bend. This led us to investigate whether linear regression was appropriate, or fails to accurately describe the data. Whilst the curve is visible, the intense density of records near the models prediction gives us an adjusted $R^{2}$ of .925 which indicates that any change in our models predictor variables will explain 92.5% of the change in our target variable.\n",
    "\n",
    "Another concern of ours was the accuracy of our prediction as the price increases. When plotting actual price against predicted price we see variability increasing as the price exceeds \\\\$7000, we have created a model, using a dataset with only those records under \\\\$7000 and above \\\\$2000. In this range our model's residuals are far more linear, with a more consistent variability. However, the statsmodels summary demonstrates that the adjusted $R^{2}$ value is lower than our full models, at .869. This is a loss of 5.6 percentage points of accuracy in price prediction. Seeing as the limited model does not provide us more accuracy than our full model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3be07",
   "metadata": {},
   "source": [
    "Overview of full model\n",
    "Overview of full model, including the variables and terms you are using in your regression model.\n",
    "\n",
    "The equation for the full model of our logistic regression is\n",
    "\n",
    "${\\widehat{price} = 559.808329 + carat \\cdot 19039.362047 + depth \\cdot 32.945903 + table \\cdot -36.347423 + x \\cdot -1669.771106 + y \\cdot 1300.930141 + z \\cdot -3054.357369 + cut_{\\text{Good}} \\cdot 493.490866 + cut_{\\text{Ideal}} \\cdot 776.568573 + cut_{\\text{Premium}} \\cdot 736.343215 + cut_{\\text{Very Good}} \\cdot 632.113751 + color_{\\text{E}} \\cdot -209.963387 + color_{\\text{F}} \\cdot -279.547224 + color_{\\text{G}} \\cdot -495.987094 + color_{\\text{H}} \\cdot -1021.892292 + color_{\\text{I}} \\cdot -649.527641 + color_{\\text{J}} \\cdot -2454.653889 + clarity_{\\text{IF}} \\cdot 5297.613834 + clarity_{\\text{SI1}} \\cdot 3655.330234 + clarity_{\\text{VS1}} \\cdot 4558.101443 + clarity_{\\text{VS2}} \\cdot 4257.575242 + clarity_{\\text{VVS1}} \\cdot 4961.013746 + clarity_{\\text{VVS2}} \\cdot 4913.601915}$\n",
    "\n",
    "Our variables in the model are described in the table below.\n",
    "\n",
    "| Variable Name | Data Type | Units | Brief description |\n",
    "|:---|:---|:---|:---|\n",
    "|**carat** | Numeric | 200 mg | Weight of the diamond\n",
    "|**cut** | Ordinal Categorical | NA | The quality of the cut (shape) of the diamond\n",
    "|**color** | Ordinal Categorical | NA | The Coloration of the diamond, the less colour the better. In ascending order, the categories are as follows (J, I, H, G, F, E, D)\n",
    "|**clarity** | Ordinal Categorical | NA | Measurement of clarity in the diamond. In ascending order, the categories are as follows (I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF)\n",
    "|**x** | Continuous Numerical | mm | Measured length of the diamond\n",
    "|**y** | Continuous Numerical | mm | Measured width of the diamond\n",
    "|**z** | Continuous Numerical | mm | Measured height of the diamond\n",
    "|**depth** | Continuous Numerical | NA | Proportion of the depth divided by the average of the x and y values\n",
    "|**table** | Continuous Numerical | NA | Width of the top of the diamond, proportionate to the widest point\n",
    "\n",
    "\n",
    "The terms we use in this report include:\n",
    "- <b> $R^{2}$ </b>: This is the measure of variance around the fitted values of regression. \n",
    "- <b> Adjusted $R^{2}$ </b>: This is a similar measure of variance, however the value changes dependent on the size of observations in a model. The intention of this adjusted value is to observe if we are overfitting the model.\n",
    "- <b> Overfitting </b>: This is when a model is needlessly complex, which can end up going against the intention of a model used to predict values that exist outside of the dataset.\n",
    "-<b> P-value </b>: In terms of linear regression, the p-value is the probability that the coefficient considered has zero effect for predicting the target variable.\n",
    "-<b> Multicollinearity </b>: This describes a scenario where there is a high degree of correlation between some of the variables in a regression model.\n",
    "-<b> Interaction Terms </b>: This is when one of our predictor variables has a different effect on the estimate, depending on the value of another predictor variable. One interaction we were keen on studying was the interaction between carat and the different qualities such as clarity, color and cut.\n",
    "-<b> Activation function </b>: This is the classification of a neuron within a neural network, it defines the rules that this neural layer will employ.\n",
    "-<b> Optimizer </b>: In neural networks, an optimizer is an algorithm that changes the elements of a network, namely the weighting and learning rates.\n",
    "-<b> Network dimensions </b>: Network dimensions describes the size of the input layer, kernel and output layer. It also describes in what dimensions the kernel can move. In our example we manipulate the amount of neurons based on the size of our input and output layer.\n",
    "-<b> Epoch </b>: The count of times a dataset is passed through and back a neural network. \n",
    "-<b> Bayesian Network </b>: A map that contains a list of probabilities of the next state based on the current state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fceb09",
   "metadata": {},
   "source": [
    "<b> Report Overview </b>\n",
    "\n",
    "In our phase 2 report, we will use python libraries to enable us to map a linear regression model to our dataset of diamond price and physical attributes, with the intention of creating a model that will accurately predict the price of a diamond based on it's physical attributes. This will involve tuning the model, possibly using feature selection and further refinement of the dataset, to increase the accuracy of our predictions. We will employ methods of investigating the residuals of our predictions against the actual observed prices to see if a linear regression model is appropriate for this dataset. We will also employ software which will allow us to leverage neural networks in modelling this linear regression. \n",
    "\n",
    "We will discuss the results of this investigation, with critiques of our model's performance, as well as any limitations we encountered. \n",
    "\n",
    "The report will end with a summary, discussing the tasks we performed across both this and our earlier report. We will present our findings and conclusions in regards to our intention of predicting diamond prices based on physical attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f56d7f",
   "metadata": {},
   "source": [
    "<b> Conclusion </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81c07d",
   "metadata": {},
   "source": [
    "As demonstrated in this report, we have achieved our intention of creating a model that can accurately predict diamond prices based on physical attributes. In the case of our neural network model, we achieved an adjusted $R^{2}$ value of 0.98. In our own research we have found that an adjusted $R^{2}$  value above .85 is very strong, which demonstrates to us that our model seems to excel in accuracy. There were concerns that our modelling would be inappropriate in regards to the nonlinearity of certain investigations, and outliers. However the full model, and neural network provide us with incredible accuracy. We can conclude that depending on the accuracy of this dataset in representing the relationship between physical characteristics and price of diamonds in the real world, our model can provide an accurate prediction for a diamonds price based on it's physical attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
