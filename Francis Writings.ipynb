{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c76589",
   "metadata": {},
   "source": [
    "Phase 1 Summary:\n",
    "\n",
    "In phase 1 we introduced our dataset 'Diamonds' and our intention for using this dataset to predict the price of diamonds based on their physical attributes. \n",
    "\n",
    "To achieve an accurate model for predicting a diamond's price, our initial task included cleaning & preprocessing the data. This involved checking for incorrect & missing values, looking at the amount of unique values, and checking the datatypes of each variable. We found records which included extreme values for the variables y and z, as well as records which included a measure of 0 for x, y and z. We removed these values as the likelihood they were meaniningful values was very low. \n",
    "\n",
    "We then began investigating the distribution of certain variables, plotting their value distribution, and their values against price.\n",
    "\n",
    "We observed that the carat variable was multimodal, with large groupings around multiples of 1 and then observable peaks again at multiples of .1. In our literature review we explored an idea of 'magic numbers' which might explain this, the theory is that jewellers would be aiming for round numbers when working with diamonds.\n",
    "\n",
    "We discovered in exploring the variable table, that it seemingly had little to no influence on price, as for almost any record of table, you could find many records outside of the upper and lower quartiles. When investigating depth we found a similar graph when plotted against price.\n",
    "\n",
    "One of the most helpful graphs for us was a scatterplot of carat against price, where each record is colored by clarity. This helped to indicate that carat had a much larger effect on price than clarity. \n",
    "\n",
    "In our literature review, we discussed the conditions of the market that influence the price of the diamonds. In particular we discussed the way in which e-commerce has the effect of changing the demand of diamonds into that of a commodity, rather than their current luxury item status. Another discussion involved the 'magic numbers' discussed earlier.\n",
    "\n",
    "The conclusion of our phase 1 report included reasonings that drive our interest in predicting diamond prices, a summary of our data processing & cleaning, as well as our findings from variable exploration.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29144be8",
   "metadata": {},
   "source": [
    "Critique and limitations:\n",
    "\n",
    "In our full model the condition number given to us by the statsmodels Ordinary Least Squares fit summary is large, at 13,400. This could be as all our data are to the right of price = 0, causing a high sensitivity around the y intercept. We can observe strange modelling in this area where the model suggests negative prices for diamonds with certain physical attributes, however a negative price is not possible for this object. Seeing as we are not interested in our model giving an accurate y intercept, as a price of zero is not possible, this is not of great concern.\n",
    "\n",
    "When plotting actual price against predicted price with the full model and full dataset we see a slight bend. This led us to investigate whether linear regression was appropriate, or fails to accurately describe the data. Whilst the curve is visible, the intense density of records near the models prediction gives us an adjusted $R^{2}$ of .922 which indicates that any change in our models predictor variables will explain 92.2% of the change in our target variable.\n",
    "\n",
    "Another concern of ours was the accuracy of our prediction as the price increases. When plotting actual price against predicted price we see variability increasing as the price exceeds \\\\$7000, we have created a model, using a dataset with only those records under \\\\$7000 and above \\\\$xxx TODO. In this range our model's residuals are far more linear, with a more consistent variability. We must consider which model provides more use to us, the original will provide a less accurate model for diamonds of any price, whereas the latter model is only intended for diamonds within a certain price range. Diamonds have a large variability in price in the real world, with prices reaching millions of dollars, however at this upper bound there are many influences on the price which may not be explained by physical characteristics, or at least, not in a linear fashion. The model with a limited bound of price would provide incredible accuracy at (TODO INSERT R^2 VALUE OF LIMITED MODEL HERE) for diamonds of a price from (TODO LOWER BOUND) - \\\\$7000. This accuracy and a range of several thousands of dollars will provide use to everyone involved in the diamond market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3be07",
   "metadata": {},
   "source": [
    "Overview of full model\n",
    "Overview of full model, including the variables and terms you are using in your regression model.\n",
    "\n",
    "The equation for the full model of our logistic regression is\n",
    "\n",
    "${\\widehat{price} = 559.808329 + carat \\cdot 19039.362047 + depth \\cdot 32.945903 + table \\cdot -36.347423 + x \\cdot -1669.771106 + y \\cdot 1300.930141 + z \\cdot -3054.357369 + cut_{\\text{Good}} \\cdot 493.490866 + cut_{\\text{Ideal}} \\cdot 776.568573 + cut_{\\text{Premium}} \\cdot 736.343215 + cut_{\\text{Very Good}} \\cdot 632.113751 + color_{\\text{E}} \\cdot -209.963387 + color_{\\text{F}} \\cdot -279.547224 + color_{\\text{G}} \\cdot -495.987094 + color_{\\text{H}} \\cdot -1021.892292 + color_{\\text{I}} \\cdot -649.527641 + color_{\\text{J}} \\cdot -2454.653889 + clarity_{\\text{IF}} \\cdot 5297.613834 + clarity_{\\text{SI1}} \\cdot 3655.330234 + clarity_{\\text{VS1}} \\cdot 4558.101443 + clarity_{\\text{VS2}} \\cdot 4257.575242 + clarity_{\\text{VVS1}} \\cdot 4961.013746 + clarity_{\\text{VVS2}} \\cdot 4913.601915}$\n",
    "\n",
    "The variables in our model are explained in our Phase 1 report. \n",
    "\n",
    "SHOULD WE WANT TO INCLUDE THIS TABLE AGAIN, HERE IT IS:\n",
    "\n",
    "| Variable Name | Data Type | Units | Brief description |\n",
    "|:---|:---|:---|:---|\n",
    "|**carat** | Numeric | 200 mg | Weight of the diamond\n",
    "|**cut** | Ordinal Categorical | NA | The quality of the cut (shape) of the diamond\n",
    "|**color** | Ordinal Categorical | NA | The Coloration of the diamond, the less colour the better. In ascending order, the categories are as follows (J, I, H, G, F, E, D)\n",
    "|**clarity** | Ordinal Categorical | NA | Measurement of clarity in the diamond. In ascending order, the categories are as follows (I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF)\n",
    "|**x** | Continuous Numerical | mm | Measured length of the diamond\n",
    "|**y** | Continuous Numerical | mm | Measured width of the diamond\n",
    "|**z** | Continuous Numerical | mm | Measured height of the diamond\n",
    "|**depth** | Continuous Numerical | NA | Proportion of the depth divided by the average of the x and y values\n",
    "|**table** | Continuous Numerical | NA | Width of the top of the diamond, proportionate to the widest point\n",
    "\n",
    "\n",
    "The terms we use in this report include:\n",
    "- <b> $R^{2}$ </b>: This is the measure of variance around the fitted values of regression. \n",
    "- <b> Adjusted $R^{2}$ </b>: This is a similar measure of variance, however the value changes dependent on the size of observations in a model. The intention of this adjusted value is to observe if we are overfitting the model.\n",
    "- <b> Overfitting </b>: This is when a model is needlessly complex, which can end up going against the intention of a model used to predict values that exist outside of the dataset.\n",
    "-<b> P-value </b>: In terms of linear regression, the p-value is the probability that the coefficient considered has zero effect for predicting the target variable.\n",
    "-<b> Multicollinearity </b>: This describes a scenario where there is a high degree of correlation between some of the variables in a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42155f9",
   "metadata": {},
   "source": [
    "<b> Report Overview </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f56d7f",
   "metadata": {},
   "source": [
    "<b> Conclusion </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb59280",
   "metadata": {},
   "source": [
    "Code snippet - measuring multi-collinearity. From https://towardsdatascience.com/linear-regression-explained-1b36f97b7572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c98416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9d83eda83444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minputy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mvif_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvif_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VIF\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "inputx = input()\n",
    "inputy = input()\n",
    "\n",
    "r = data_encoded[[inputx,inputy]].values\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(r, i) for i in range(2)]\n",
    "vif_df[\"feature\"] = [inputx, inputy]\n",
    "vif_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
